{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Credit Scoring\n",
    "\n",
    "This notebook performs EDA on a credit dataset to uncover patterns, assess data quality, and identify key predictors of creditworthiness. The analysis includes data cleaning, univariate and bivariate analysis, visualizations, and fairness checks.\n",
    "\n",
    "## Dataset\n",
    "Assumes a credit dataset (e.g., Kaggle Credit Risk Dataset) with columns like `loan_amnt`, `int_rate`, `grade`, `default` (target), etc. Place the dataset in `data/raw/credit_data.csv`.\n",
    "\n",
    "## Steps\n",
    "1. Load and clean the dataset.\n",
    "2. Summarize data (statistics, missing values).\n",
    "3. Analyze distributions and relationships.\n",
    "4. Generate visualizations.\n",
    "5. Identify key predictors and check for potential biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import custom modules from src/\n",
    "from src.data_preprocessing import load_data, clean_data, save_cleaned_data\n",
    "from src.visualizations import plot_distribution, plot_correlation_heatmap, plot_default_by_category\n",
    "from src.analysis import summarize_data, correlation_analysis, chi_square_test\n",
    "\n",
    "# Set output directory for figures\n",
    "os.makedirs('../reports/figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Clean Data\n",
    "\n",
    "Load the raw dataset and apply cleaning steps (handle missing values, encode categorical variables, remove outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_path = '../data/raw/credit_data.csv'\n",
    "df = load_data(data_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Raw Data Preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Clean dataset\n",
    "df_clean = clean_data(df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "save_cleaned_data(df_clean, '../data/processed/credit_data_cleaned.csv')\n",
    "\n",
    "# Display cleaned data preview\n",
    "print(\"\\nCleaned Data Preview:\")\n",
    "print(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Summary\n",
    "\n",
    "Generate summary statistics, check for missing values, and review data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize data\n",
    "summary = summarize_data(df_clean)\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary['numerical'])\n",
    "print(\"\\nMissing Values:\")\n",
    "print(summary['missing'])\n",
    "print(\"\\nData Types:\")\n",
    "print(summary['data_types'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis\n",
    "\n",
    "Analyze the distribution of key numerical features (e.g., loan amount, interest rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions for key numerical columns\n",
    "numerical_cols = ['loan_amnt', 'int_rate']  # Adjust based on your dataset\n",
    "for col in numerical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        plot_distribution(df_clean, col, '../reports/figures')\n",
    "        print(f\"Distribution plot for {col} saved.\")\n",
    "    else:\n",
    "        print(f\"Column {col} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bivariate and Multivariate Analysis\n",
    "\n",
    "Analyze relationships between features and the target variable (`default`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis with target variable\n",
    "target = 'default'  # Adjust based on your target column\n",
    "if target in df_clean.columns:\n",
    "    correlations = correlation_analysis(df_clean, target)\n",
    "    print(\"Correlations with Default:\")\n",
    "    print(correlations)\n",
    "    plot_correlation_heatmap(df_clean, '../reports/figures')\n",
    "    print(\"Correlation heatmap saved.\")\n",
    "else:\n",
    "    print(f\"Target column {target} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze default rates by categorical variables\n",
    "categorical_cols = ['grade']  # Adjust based on your dataset\n",
    "for col in categorical_cols:\n",
    "    if col in df_clean.columns:\n",
    "        plot_default_by_category(df_clean, col, target, '../reports/figures')\n",
    "        print(f\"Default rate plot for {col} saved.\")\n",
    "        # Perform chi-square test\n",
    "        chi2_result = chi_square_test(df_clean, col, target)\n",
    "        print(f\"Chi-Square Test for {col}:\")\n",
    "        print(chi2_result)\n",
    "    else:\n",
    "        print(f\"Column {col} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness and Bias Check\n",
    "\n",
    "Check for potential biases in sensitive attributes (e.g., gender, age group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Default rates by a sensitive attribute (e.g., age group)\n",
    "sensitive_col = 'age'  # Adjust based on your dataset\n",
    "if sensitive_col in df_clean.columns:\n",
    "    plot_default_by_category(df_clean, sensitive_col, target, '../reports/figures')\n",
    "    print(f\"Default rate plot for {sensitive_col} saved.\")\n",
    "    chi2_result = chi_square_test(df_clean, sensitive_col, target)\n",
    "    print(f\"Chi-Square Test for {sensitive_col}:\")\n",
    "    print(chi2_result)\n",
    "else:\n",
    "    print(f\"Sensitive column {sensitive_col} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings and Next Steps\n",
    "\n",
    "- **Key Predictors**: Based on correlations and chi-square tests, [e.g., loan_amnt, int_rate, grade] are likely strong predictors.\n",
    "- **Data Quality**: [Summarize missing values, outliers handled].\n",
    "- **Potential Biases**: [Note any concerning patterns in sensitive attributes].\n",
    "- **Next Steps**: Use cleaned dataset (`data/processed/credit_data_cleaned.csv`) for feature engineering and model development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 
